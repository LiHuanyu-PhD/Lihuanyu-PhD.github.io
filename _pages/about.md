---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html

---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}


<style>
  .intro-section h1 {
    font-size: 28px;
    font-weight: bold;
    margin-bottom: 0.5em;
  }
  .intro-section p {
    font-size: 18px;
    line-height: 1.6;
    text-align: justify;
  }
 li {
  text-align: justify;
  line-height: 1.7;
}
</style>
<div class="intro-section" id='about-me'>
  <h1>Welcome to Huanyu Li (ç¯å®‡ æ)'s Homepage</h1>
  <p>
    I am currently enrolled in a doctoral program at the College of Marine Spatial Information, China University of Petroleum (East China), where my research focuses on underwater intelligent image processing and deep model compression.
  </p>
</div>

# ğŸš€ News

- Jan. 2025, ğŸ‰Our works "<a href="https://link.springer.com/article/10.1007/s11263-025-02650-w" style="text-decoration: none;">Large Foundation Model Empowered Region-aware Underwater Image Captioning</a>" (<strong><i> International Journal of Computer Vision</i></strong>) have been <strong style="color:red;">published</strong>!
- Jul. 2025,ğŸ†Our works "<a href="https://ieeexplore.ieee.org/document/11062881" style="text-decoration: none;">Underwater Image Captioning With AquaSketch-Enhanced Cross-Scale Information Fusion</a>" (<strong><i> IEEE Transactions on Geoscience and Remote Sensing</i></strong>) and "<a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253525003422" style="text-decoration: none;">Underwater image captioning via attention mechanism based fusion of visual and textual information</a>" (<strong><i> Information Fusion</i></strong>) has been newly selected as <strong style="color:red;">ESI Highly Cited Papers</strong>!
- Jun. 2025, ğŸ‰Our works "<a href="https://pdf.sciencedirectassets.com/271826/1-s2.0-S0924271624X00155/1-s2.0-S0924271624004726/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIAfjeMw2%2BJm8yYcdbS7A1DrDa2c5iBwMU3DrD77I8wBoAiEAqvppWcVwotGcH9yoXBYLi%2B9XxiUMs%2Fceia%2F6SUlmaBwqugUIv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDGGyBvW%2FpbI4hX%2BDFSqOBby6HckHsoz1MIk7hP%2FBslZev99kPiawc2fti4RGfppOlfwws3Yb6eAuKo7DdSwB0JHyGYOHI7e6nS1NkfZUSSCG%2BPRDqATjH4lQOF8UIziJS0TR81NKxIINtCyMOA9ih%2Fqz%2BWuMrSFagCfir8CF%2B%2BwQDB2rp8pIWsayvLeuXL%2BgpyzXZr0jKuGsYKN7vIS6n4nGW%2FbAJVNvKDr1FtkQ9zVRf7RasKbN%2BoJwbUjynwBZtGu5K3TJWMWVwZKS9SR%2ByTqdd9xHDrkdp0lR4olB%2Bq%2F8ybTjOSngK6Oixg5Y220muV7W7WL2Ux%2FrAs2ODKViP35PkWLmDaYgvs2wxB7%2FeqU%2BEZ9k2PjljkXLF%2FjV5vKCtE%2Fjgd386hEo%2BbL1ww%2BJAcm8Mf36Pz3scr0qWIC9QW2vCJDOShRVbQd4qsH0EZuDjKK%2FQ8HGvPaV4pxlP%2BqnIkmQuBG%2Fy%2FFDA9VBcfFZ9QElmBva6qscmlo8E9V5C43ps%2BJYHYg2TTGunBAye3US0ce0%2BbftL4k4sRHVbU%2FhGpHhl3pCzyB51TqbRh2PRPT36QBX56YyT%2BXNW1vidU%2B%2Fugtyah9VRBqsR2kf%2F0SvoxxD3y%2F3jj6e1TY05uDf8xnsyMMSNI3R4W4UeNk5pWLT8lMR9bP5slZzmaLoLW%2FZ2QWoociweJ5Z47SuMmqnHY3KoPXFUXVEVHflfy2wRgI8Rq1hqpFnLB2lXXxJTuRKZBIJXgIjiRXKaFqHPSe3RO%2BX8dWtz5%2Bq0AzIwa2tW%2F3dQJLNoIQp0Zz7sJv4yPuOHNcP494TjjMkaHZQ4r%2BpKKsBS%2FXb0B7cD2Zc%2FwO%2FX3RsrtlF%2FQoYWD1WGaWuOk3PCJFU1qrzwLU%2FLb0Hq1HdKjC%2B5aDCBjqxAST0emrLrGrHm8ICsktUR5KjiQHDBUiheCEPTFE4n0NGTWujObwqqXcmp1X2TqTHHWnyX6TzF9%2BoPDhGLetNetwliQbO6Q9kK6DLf0AmAI8wD6S5Dk1idxaiBvojtYKOBcEULa%2B77tZhMATCDbwWP%2FArIuOUqhN1B73siyu%2FEW5ItGGDU1F%2F5FtNprfLSJXz%2BAKKzTrRd25suK6zlA740k0eWwNcbbGcglx93jK9ZgVmLw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250610T144618Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYQ4JGAUIX%2F20250610%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=fde4a853f176c070d7d1f5b4fc80373d408fe58e11f6f1e2883d71915360605c&hash=46757d66d23713a4c25e1fb63c48255e3e2a5979bb7d72b2be605db5f3a2e9ea&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0924271624004726&tid=spdf-6a25aef3-97e6-4e25-ab89-3f1a072a0255&sid=e4a868d6227f3248102b6a5381ef6445435fgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=05005c57065e0f5e5659&rr=94d9a8499bb58515&cc=cn&kca=eyJrZXkiOiJ6MWo5TXVUNmU1Rjg3R2ljWFBIZHpjaE5xNWVYNzVNdW9OY0k5bzFiQ2tZaFA5bXcxd1RTZDNWNkdQc3JjM25MWXBkaThkMWs0YW92dm9PNkJ3T2ZMZjZ5VVRmTzJlUi8xRDVVQ2RuZE9hTS9IbXdkUU5oU0plOFhQajUrUDI4aFFERFRCc20zVC9QSWJVcURiUlFkQ2kwaEVmUDJrQ3BIdFZ6Y0l3aktwT0w4QmhzPSIsIml2IjoiZDA3YmNhNzJhZGU5M2VlYTBjMzJlYWUzY2FhMjBkNGMifQ==_1749566790377" style="text-decoration: none;">Underwater Image Captioning with AquaSketch-Enhanced Cross-Scale Information Fusion</a>" (<strong><i>IEEE Transactions on Geoscience and Remote Sensing</i></strong>) have been <strong style="color:red;">published</strong>!

- May. 2025, ğŸ† Our works "<a href="https://www.sciencedirect.com/science/article/pii/S0924271624004726" style="text-decoration: none;">Underwater image captioning: Challenges, models, and datasets</a>" (<strong><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></strong>) have been newly selected as <strong style="color:red;">ESI Hot Paper</strong>!

- Apr. 2025, ğŸ‰Our works "<a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253525003422" style="text-decoration: none;">Underwater image captioning via attention mechanism based fusion of visual and textual information</a>" (***Information Fusion***) have been <strong style="color:red;">published</strong>!

- Feb. 2025, ğŸ†Our work "<a href="https://www.sciencedirect.com/science/article/pii/S0924271624004726" style="text-decoration: none;">Underwater image captioning: Challenges, models, and datasets</a>"( <strong><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></strong> ) has been selected as the <strong style="color:red;">Feature Article</strong> in February 2025 (the only article selected that month)!
- Jan. 2025, ğŸ‰Our work "<a href="https://www.sciencedirect.com/science/article/pii/S0924271624004726" style="text-decoration: none;">Underwater image captioning: Challenges, models, and datasets</a>" ( <strong><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></strong> ) has been <strong style="color:red;">published</strong>!! 

# ğŸ“ Publications

- <strong><u>Huanyu Li</u></strong>, Li Li, Hao Wang, Weibo Zhang, Peng Ren. <a href="https://link.springer.com/article/10.1007/s11263-025-02650-w" style="text-decoration: none;">Large Foundation Model Empowered Region-aware Underwater Image Captioning</a>. <strong><i>International Journal of Computer Vision</i></strong>, 2026. [<strong style="color:red;">CCF-A</strong>] 
- <strong><u>Huanyu Li</u></strong>, Li Li, Hao Wang, Weibo Zhang, Peng Ren. <a href="https://ieeexplore.ieee.org/document/11062881" style="text-decoration: none;">Underwater Image Captioning With AquaSketch-Enhanced Cross-Scale Information Fusion</a>. <strong><i>IEEE Transactions on Geoscience and Remote Sensing</i></strong>, 2025.   [<strong style="color:red;">**ESI Highly Cited Paper**</strong>] 
- Li Li, <strong><u>Huanyu Li</u></strong>, Peng Ren. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253525003422" style="text-decoration: none;">Underwater image captioning via attention mechanism based fusion of visual and textual information</a>.  ***Information Fusion***, 2025. [<strong style="color:red;">**ESI Highly Cited Paper**</strong>] 
- <strong><u>Huanyu Li</u></strong>, Hao Wang, Ying Zhang, Li Li, Peng Ren. <a href="https://www.sciencedirect.com/science/article/pii/S0924271624004726" style="text-decoration: none;">Underwater image captioning: Challenges, models, and datasets</a>. <strong><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></strong>, 2025. [<strong style="color:red;">ESI Hot Paper, ESI Highly Cited Paper & ISPRS Featured Articles</strong>] 
- Ying Zhang, <strong><u>Huanyu Li</u></strong>, Bingyu Li, Li Li, Weibo Zhang, Hao Wang, Peng Ren.  <a href="https://link.springer.com/article/10.1007/s44295-025-00054-7" style="text-decoration: none;">An underwater acoustic semantic communication approach to underwater image transmission</a>. ***Intelligent Marine Technology and Systems***, 2025. 
- Chunlei Li, <strong><u>Huanyu Li</u></strong>, Guangshuai Gao, Zhoufeng Liu, Pengcheng Liu.  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1568494623003447" style="text-decoration: none;">An accelerating convolutional neural networks via a 2D entropy based-adaptive filter search method for image recognition</a>. ***Applied Soft Computing***ï¼Œ2023. 

# ğŸ“š Educations

- 2022 - 2025, PhD in Marine Resources and Information Engineering, China University of Petroleum (East China), China. 
- 2019 - 2022, MEng in Signal and Information Processing, Zhongyuan University of Technology, China. (MS Thesis: Research on structured pruning method and hardwareacceleration of convolutional neural network)
- 2015 - 2019, BEng in Automation, Zhongyuan University of Technology, China.

# ğŸŒ Academic Services

## ğŸ“ Peer Review Experience (Reviewed over 300 manuscripts for more than 20 academic journals)

### ğŸ”„**Continuous Reviewer** (2023 â€“ Present) for:

- *IEEE Transactions on Geoscience and Remote Sensing,*
- *Pattern Recognition*
- *Engineering Applications of Artificial Intelligence*
- *Neural Networks*
- *Applied Soft Computing*
- *IEEE Journal of Oceanic Engineering*
- *IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing*
- *Neural Computing and Applications*
-  *The Visual Computer*
- *Signal, Image and Video Processing*
- *â€¦and more.*

## ğŸ– Selected Honors and Awards

- Oct. 2025:ğŸ–ï¸ Awarded the [Outstanding Master's Thesis](http://m.jyt.henan.gov.cn/2023/08-12/2795956.html) of Henan Province.

